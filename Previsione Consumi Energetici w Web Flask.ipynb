{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24976a63",
   "metadata": {},
   "source": [
    "# Predizione dei Consumi Energetici nell'Industria Siderurgica\n",
    "\n",
    "**Studente**: Massimiliano Camillucci  \n",
    "**Matricola**: 0001087333  \n",
    "**Corso**: Programmazione di Applicazioni Data Intensive A.A. 2024/2025\n",
    "\n",
    "## Dataset ##\n",
    "**Dataset utilizzato**: Steel Industry Energy Consumption (Kaggle/UCI Repository)\n",
    "- **35.040 misurazioni** prese ogni 15 minuti per 6 mesi\n",
    "- **Obiettivo**: prevedere `Usage_kWh` (quanta energia viene consumata)\n",
    "- **10 variabili** che descrivono lo stato dell'impianto\n",
    "- **Link**: https://www.kaggle.com/datasets/csafrit2/steel-industry-energy-consumption\n",
    "\n",
    "## Descrizione del Problema\n",
    "In questo progetto analizziamo i dati di consumo energetico di un'industria siderurgica per creare un modello che possa **prevedere quanto energia verrà consumata** in base alle condizioni operative dell'impianto.\n",
    "\n",
    "**Perché è importante?**\n",
    "- Aiuta l'azienda a pianificare meglio la produzione\n",
    "- Permette di ottimizzare i costi energetici\n",
    "- Contribuisce a ridurre gli sprechi di energia\n",
    "\n",
    "**Cosa misuriamo**:\n",
    "- **Variabili numeriche**: potenze elettriche, fattori di efficienza, emissioni CO2\n",
    "- **Variabili categoriche**: tipo di lavorazione, giorno della settimana, se è weekend\n",
    "\n",
    "Il nostro compito è capire **quali fattori influenzano di più** il consumo energetico e costruire un modello accurato per le previsioni."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ad0ab8",
   "metadata": {},
   "source": [
    "## 1. Caricamento e Descrizione Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1cd6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('Steel_industry_data.csv')\n",
    "print(f\"Dataset caricato! Dimensioni: {df.shape[0]} righe  {df.shape[1]} colonne\")\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e9c081",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"STATISTICHE\")\n",
    "print(\"(media, deviazione standard, minimo, massimo, ecc.)\")\n",
    "df.describe()\n",
    "\n",
    "print(f\"Totale valori mancanti nel dataset: {df.isnull().sum().sum()}\")\n",
    "\n",
    "print(\"\\nVARIABILI CATEGORICHE\")\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    unique_values = df[col].unique()\n",
    "    print(f\"{col}: {len(unique_values)} categorie diverse\")\n",
    "    print(f\"  Valori: {list(unique_values)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf72b7f",
   "metadata": {},
   "source": [
    "### 1.1 Significato delle variabili nel contesto industriale\n",
    "\n",
    "***Variabili Elettriche (Energia e Potenza)*** - Mostrano l'efficienza dell'impianto\n",
    "- **`Lagging_Current_Reactive.Power_kVarh`**: Energia reattiva assorbita dall'impianto. Indica inefficienze nei carichi induttivi (motori, trasformatori). Valori alti = maggiori sprechi energetici.\n",
    "- **`Leading_Current_Reactive_Power_kVarh`**: Energia reattiva restituita alla rete. Può indicare presenza di condensatori per correzione del fattore di potenza.\n",
    "- **`Lagging_Current_Power_Factor`**: Fattore di potenza induttivo (%). Misura l'efficienza energetica: 100% = massima efficienza.\n",
    "- **`Leading_Current_Power_Factor`**: Fattore di potenza capacitivo (%). Indica la gestione dei carichi capacitivi.\n",
    "\n",
    "***Variabili Temporali*** - Catturano i pattern operativi (turni, stagionalità)\n",
    "- **`NSM`**: Secondi dalla mezzanotte (0-86400). Variabile temporale continua per pattern orari dettagliati.\n",
    "- **`hour`**: Ora del giorno (0-23). Fondamentale per turni di lavoro, pause, picchi di consumo.\n",
    "- **`month`**: Mese dell'anno (1-12). Cattura variazioni stagionali: temperatura, domanda, manutenzioni.\n",
    "\n",
    "***Variabili Operative*** - intensità produttiva\n",
    "- **`WeekStatus`**: Weekday/Weekend. Negli impianti industriali i weekend hanno consumi molto diversi.\n",
    "- **`Day_of_week`**: Monday-Sunday. Pattern specifici: lunedì = riavvio impianti, venerdì = rallentamenti.\n",
    "- **`Load_Type`**: Light/Medium/Maximum Load. Riflette il livello produttivo dell'impianto.\n",
    "\n",
    "Queste variabili ci ermettono di capire **quando** e **perché** si consuma più energia\n",
    "\n",
    "***Variabile Target***\n",
    "- **`Usage_kWh`**: Consumo energetico totale che vogliamo prevedere. È il risultato dell'interazione di tutti i fattori precedenti.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb133652",
   "metadata": {},
   "source": [
    "## 2. Analisi Esplorativa dei Dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a444eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: Analisi della variabile che vogliamo prevedere (Usage_kWh)\n",
    "\n",
    "# Creiamo due grafici affiancati per capire come sono distribuiti i consumi\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Grafico 1: Istogramma - mostra quante volte si ripetono certi valori di consumo\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df['Usage_kWh'], bins=30, alpha=0.7, color='skyblue')\n",
    "plt.title('Come sono distribuiti i consumi energetici')\n",
    "plt.xlabel('Consumo energetico (kWh)')\n",
    "plt.ylabel('Numero di osservazioni')\n",
    "\n",
    "# Grafico 2: Boxplot - mostra valori centrali e eventuali outlier\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot(df['Usage_kWh'], patch_artist=True, \n",
    "            boxprops=dict(facecolor='lightblue'))\n",
    "plt.title('Boxplot dei consumi energetici')\n",
    "plt.ylabel('Consumo energetico (kWh)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calcoliamo alcune statistiche utili\n",
    "print(\"=== STATISTICHE CONSUMI ENERGETICI ===\")\n",
    "print(f\"Consumo medio: {df['Usage_kWh'].mean():.2f} kWh\")\n",
    "print(f\"Consumo più frequente (mediana): {df['Usage_kWh'].median():.2f} kWh\")\n",
    "print(f\"Variabilità (deviazione standard): {df['Usage_kWh'].std():.2f} kWh\")\n",
    "print(f\"Consumo minimo: {df['Usage_kWh'].min():.2f} kWh\")\n",
    "print(f\"Consumo massimo: {df['Usage_kWh'].max():.2f} kWh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f382d540",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "#Consumo per tipo di lavorazione/carico\n",
    "plt.subplot(1, 3, 1)\n",
    "df.boxplot(column='Usage_kWh', by='Load_Type', ax=plt.gca())\n",
    "plt.title('Consumo per Tipo di Lavorazione')\n",
    "plt.suptitle('')  # Rimuove il titolo automatico del boxplot\n",
    "plt.xlabel('Tipo di Lavorazione')\n",
    "plt.ylabel('Consumo (kWh)')\n",
    "\n",
    "#Consumo per giorno della settimana\n",
    "plt.subplot(1, 3, 2)\n",
    "df.boxplot(column='Usage_kWh', by='Day_of_week', ax=plt.gca())\n",
    "plt.title('Consumo per Giorno della Settimana')\n",
    "plt.suptitle('')\n",
    "plt.xlabel('Giorno della Settimana')\n",
    "plt.ylabel('Consumo (kWh)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Consumo weekend vs giorni lavorativi\n",
    "plt.subplot(1, 3, 3)\n",
    "df.boxplot(column='Usage_kWh', by='WeekStatus', ax=plt.gca())\n",
    "plt.title('Consumo Weekend vs Settimana')\n",
    "plt.suptitle('')\n",
    "plt.xlabel('Tipo di Giorno')\n",
    "plt.ylabel('Consumo (kWh)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "for load_type in df['Load_Type'].unique():\n",
    "    avg_consumption = df[df['Load_Type'] == load_type]['Usage_kWh'].mean()\n",
    "    print(f\"• {load_type}: consumo medio {avg_consumption:.1f} kWh\")\n",
    "\n",
    "print(f\"\\n• Weekend: consumo medio {df[df['WeekStatus'] == 'Weekend']['Usage_kWh'].mean():.1f} kWh\")\n",
    "print(f\"• Giorni lavorativi: consumo medio {df[df['WeekStatus'] == 'Weekday']['Usage_kWh'].mean():.1f} kWh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b966726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlazioni \n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "correlation_matrix = df[numeric_cols].corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "plt.title('Mappa delle Correlazioni\\n(Rosso = correlazione positiva, Blu = correlazione negativa)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "target_corr = correlation_matrix['Usage_kWh'].sort_values(key=abs, ascending=False)\n",
    "print(\"(1.0 = correlazione max, 0.0 = nessuna correlazione)\")\n",
    "print()\n",
    "for variable, correlation in target_corr.items():\n",
    "    if variable != 'Usage_kWh':  # Escludo il target \n",
    "        direction = \"positiva\" if correlation > 0 else \"negativa\"\n",
    "        strength = \"forte!!\" if abs(correlation) > 0.8 else \"forte\" if abs(correlation) > 0.6 else \"moderata\" if abs(correlation) > 0.3 else \"debole\"\n",
    "        print(f\"• {variable}: {correlation:.3f} ({direction}, {strength})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0d06ac",
   "metadata": {},
   "source": [
    "### 2.1 Analisi possibile \"Data Leakage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2499ca57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variabili con correlazione molto alta (>0.9) con il target\n",
    "high_corr_threshold = 0.9\n",
    "high_correlations = target_corr[abs(target_corr) > high_corr_threshold]\n",
    "high_correlations = high_correlations.drop('Usage_kWh')  # Rimuovo il target stesso\n",
    "\n",
    "print(\"Variabili con correlazione troppo alta (>0.9):\")\n",
    "for var, corr in high_correlations.items():\n",
    "    print(f\"  • {var}: {corr:.4f} ⚠️\")\n",
    "\n",
    "# Analizziamo la CO2\n",
    "if 'CO2(tCO2)' in df.columns:\n",
    "    co2_corr = correlation_matrix.loc['CO2(tCO2)', 'Usage_kWh']\n",
    "    print(f\"Correlazione CO2 con Usage_kWh: {co2_corr:.4f}\")\n",
    "    \n",
    "    df['CO2_per_kWh'] = df['CO2(tCO2)'] / df['Usage_kWh']\n",
    "    ratio_std = df['CO2_per_kWh'].std()\n",
    "    ratio_mean = df['CO2_per_kWh'].mean()\n",
    "    cv = ratio_std / ratio_mean  # Quanto varia il rapporto?\n",
    "    \n",
    "    print(f\"Rapporto medio CO2/kWh: {ratio_mean:.6f}\")\n",
    "    print(f\"Variabilità del rapporto: {cv:.6f}\")\n",
    "    \n",
    "    print(\"\\n Escludiamo CO2 per sicurezza\")\n",
    "    print(\"Le emissioni CO2 spesso dipendono direttamente dal consumo energetico\")\n",
    "\n",
    "# Creiamo grafici per visualizzare il problema\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(df['Usage_kWh'], df['CO2(tCO2)'], alpha=0.6, s=1, color='red')\n",
    "plt.xlabel('Consumo Energetico (kWh)')\n",
    "plt.ylabel('Emissioni CO2 (tCO2)')\n",
    "plt.title(f'Relazione CO2 vs Consumo\\nCorrelazione: {co2_corr:.3f}')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(df['CO2_per_kWh'], bins=50, alpha=0.7, color='orange', edgecolor='black')\n",
    "plt.xlabel('CO2 per kWh')\n",
    "plt.ylabel('Frequenza')\n",
    "plt.title(f'Quanto varia il rapporto CO2/kWh?\\nVariabilità: {cv:.4f}')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Lista finale delle variabili da escludere\n",
    "leakage_vars = list(high_correlations.index)\n",
    "print(f\"\\n📋 VARIABILI DA ESCLUDERE: {leakage_vars}\")\n",
    "print(f\"📊 Variabili rimanenti per il modello: {len(numeric_cols) - len(leakage_vars) - 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2615dc4",
   "metadata": {},
   "source": [
    "### 2.2 Analisi Temporale - Come cambia il consumo nel tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f588898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern temporali: quando si consuma di più?\n",
    "\n",
    "# convertiamo la data\n",
    "df['date'] = pd.to_datetime(df['date'], format='%d/%m/%Y %H:%M', dayfirst=True)\n",
    "df['hour'] = df['date'].dt.hour    # Estraiamo ora\n",
    "df['month'] = df['date'].dt.month  # Estraiamo mese\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Consumo durante il giorno (24 ore)\n",
    "plt.subplot(2, 2, 1)\n",
    "hourly_consumption = df.groupby('hour')['Usage_kWh'].mean()\n",
    "plt.plot(hourly_consumption.index, hourly_consumption.values, marker='o', linewidth=2, color='blue')\n",
    "plt.title('Consumo nelle 24 ore del giorno')\n",
    "plt.xlabel('Ora')\n",
    "plt.ylabel('Consumo medio (kWh)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(range(0, 24, 2))\n",
    "\n",
    "# Consumo nei diversi mesi\n",
    "plt.subplot(2, 2, 2)\n",
    "monthly_consumption = df.groupby('month')['Usage_kWh'].mean()\n",
    "plt.bar(monthly_consumption.index, monthly_consumption.values, color='green', alpha=0.7)\n",
    "plt.title('Consumo nei diversi mesi')\n",
    "plt.xlabel('Mese')\n",
    "plt.ylabel('Consumo medio (kWh)')\n",
    "plt.xticks(range(1, 13))\n",
    "\n",
    "# Consumo per tipo di lavorazione\n",
    "plt.subplot(2, 2, 3)\n",
    "load_type_stats = df.groupby('Load_Type')['Usage_kWh'].agg(['mean', 'std'])\n",
    "plt.bar(load_type_stats.index, load_type_stats['mean'], \n",
    "        yerr=load_type_stats['std'], capsize=5, color='orange', alpha=0.7)\n",
    "plt.title('Consumo per Tipo di Lavorazione (±deviazione)')\n",
    "plt.xlabel('Tipo di Lavorazione')\n",
    "plt.ylabel('Consumo (kWh)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Mappa di consumo ora vs tipo lavorazione\n",
    "plt.subplot(2, 2, 4)\n",
    "pivot_table = df.pivot_table(values='Usage_kWh', index='hour', columns='Load_Type', aggfunc='mean')\n",
    "sns.heatmap(pivot_table, annot=True, fmt='.1f', cmap='YlOrRd')\n",
    "plt.title('Mappa: Consumo per Ora e Tipo Lavorazione')\n",
    "plt.xlabel('Tipo di Lavorazione')\n",
    "plt.ylabel('Ora del Giorno')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    " \n",
    "print(\"=== TIPO DI LAVORAZIONE ===\")\n",
    "for load_type in df['Load_Type'].unique():\n",
    "    subset = df[df['Load_Type'] == load_type]\n",
    "    print(f\"\\n🏭 {load_type}:\")\n",
    "    print(f\"   Consumo medio: {subset['Usage_kWh'].mean():.1f} kWh\")\n",
    "    print(f\"   Consumo tipico: {subset['Usage_kWh'].median():.1f} kWh\")\n",
    "    print(f\"   Variabilità: {subset['Usage_kWh'].std():.1f} kWh\")\n",
    "    print(f\"   Numero misurazioni: {len(subset):,}\")\n",
    "    print(f\"   % del totale: {len(subset)/len(df)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c564890",
   "metadata": {},
   "source": [
    "## 3. Preparazione Dati per Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41be768",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Usage_kWh', 'date'], axis=1)  # Variabili predittive\n",
    "y = df['Usage_kWh']                         # Variabile da prevedere\n",
    "\n",
    "print(f\"Variabili predittive: {X.shape[1]} colonne, {X.shape[0]} righe\")\n",
    "print(f\"Variabile target: {y.shape[0]} valori\")\n",
    "\n",
    "numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"\\nVariabili numeriche ({len(numeric_features)}): {numeric_features}\")\n",
    "print(f\"Variabili categoriche ({len(categorical_features)}): {categorical_features}\")\n",
    "\n",
    "leakage_vars = ['CO2(tCO2)', 'CO2_per_kWh']\n",
    "print(f\"\\nEscludiamo queste variabili per evitare il data leakage: {leakage_vars}\")\n",
    "\n",
    "X_clean = X.drop(columns=[col for col in leakage_vars if col in X.columns])\n",
    "numeric_features_clean = [f for f in numeric_features if f not in leakage_vars]\n",
    "\n",
    "print(f\"\\nDataset finale: {X_clean.shape[1]} variabili, {X_clean.shape[0]} osservazioni\")\n",
    "print(f\"Variabili numeriche pulite ({len(numeric_features_clean)}): {numeric_features_clean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435e63d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded = X_clean.copy()\n",
    "label_encoders = {} \n",
    "\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()  \n",
    "    X_encoded[col] = le.fit_transform(X_clean[col])\n",
    "    label_encoders[col] = le  \n",
    "    original_values = X_clean[col].unique()\n",
    "    encoded_values = le.transform(original_values)\n",
    "    print(f\"\\n📝 {col}:\")\n",
    "    for orig, enc in zip(original_values, encoded_values):\n",
    "        print(f\"   '{orig}' → {enc}\")\n",
    "\n",
    "X_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a61bf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dati in training (70%) e test (30%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y, test_size=0.3, random_state=42  \n",
    ")\n",
    "\n",
    "print(f\"Set di training: {X_train.shape[0]} osservazioni\")\n",
    "print(f\"Set di test: {X_test.shape[0]} osservazioni\")\n",
    "\n",
    "scaler = StandardScaler() \n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "X_train_scaled[numeric_features_clean] = scaler.fit_transform(X_train[numeric_features_clean])\n",
    "X_test_scaled[numeric_features_clean] = scaler.transform(X_test[numeric_features_clean])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d74055",
   "metadata": {},
   "source": [
    "## 4. Training e Validazione Modelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78df1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    train_mse = mean_squared_error(y_train, y_pred_train)  # Errore quadratico medio\n",
    "    test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "    train_r2 = r2_score(y_train, y_pred_train)  # R2 \n",
    "    test_r2 = r2_score(y_test, y_pred_test)\n",
    "    \n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  Training → MSE: {train_mse:.2f}, R²: {train_r2:.4f}\")\n",
    "    print(f\"  Test → MSE: {test_mse:.2f}, R²: {test_r2:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'train_mse': train_mse,\n",
    "        'test_mse': test_mse,\n",
    "        'train_r2': train_r2,\n",
    "        'test_r2': test_r2\n",
    "    }\n",
    "\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39b0246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELLO 1: Regressione Lineare Semplice\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "results['Linear Regression'] = evaluate_model(\n",
    "    lr_model, X_train_scaled, X_test_scaled, y_train, y_test, \"Regressione Lineare\"\n",
    ")\n",
    "\n",
    "feature_importance_lr = pd.DataFrame({\n",
    "    'feature': X_train_scaled.columns,\n",
    "    'coefficient': abs(lr_model.coef_) \n",
    "}).sort_values('coefficient', ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 variabili più importanti (Regressione Lineare):\")\n",
    "print(feature_importance_lr.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439b358c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELLO 2: Random Forest\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "results['Random Forest'] = evaluate_model(\n",
    "    rf_model, X_train_scaled, X_test_scaled, y_train, y_test, \"Random Forest\"\n",
    ")\n",
    "\n",
    "feature_importance_rf = pd.DataFrame({\n",
    "    'feature': X_train_scaled.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 variabili più importanti (Random Forest):\")\n",
    "print(feature_importance_rf.head())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance_rf['feature'][:8], feature_importance_rf['importance'][:8])\n",
    "plt.title('Importanza delle Variabili - Random Forest')\n",
    "plt.xlabel('Importanza')\n",
    "plt.gca().invert_yaxis()  # La variabile più importante in alto\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5de1f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELLO 3: Ridge Regression\n",
    "ridge_model = Ridge(alpha=1.0) \n",
    "results['Ridge'] = evaluate_model(\n",
    "    ridge_model, X_train_scaled, X_test_scaled, y_train, y_test, \"Ridge Regression\"\n",
    ")\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'Test MSE': [results[model]['test_mse'] for model in results.keys()],\n",
    "    'Test R²': [results[model]['test_r2'] for model in results.keys()]\n",
    "})\n",
    "\n",
    "print(\"\\nConfronto performance dei modelli (ordinati per MSE crescente):\")\n",
    "print(comparison_df.sort_values('Test MSE'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49196b15",
   "metadata": {},
   "source": [
    "## 5. Ottimizzazione Iperparametri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98fa4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100],        # Numero di alberi nella foresta\n",
    "    'max_depth': [10, 20],            # Profondità massima degli alberi\n",
    "    'min_samples_split': [2, 5]       # Campioni minimi per dividere un nodo\n",
    "}\n",
    "\n",
    "total_combinations = len(param_grid['n_estimators']) * len(param_grid['max_depth']) * len(param_grid['min_samples_split'])\n",
    "print(f\"Testando {total_combinations} combinazioni di parametri...\")\n",
    "\n",
    "# Grid Search\n",
    "rf_grid = GridSearchCV(\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,  # 5-fold cross validation \n",
    "    scoring='neg_mean_squared_error', \n",
    "    n_jobs=-1  \n",
    ")\n",
    "\n",
    "rf_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\n Migliori parametri trovati: {rf_grid.best_params_}\")\n",
    "print(f\"Miglior MSE in cross-validation: {-rf_grid.best_score_:.2f}\")\n",
    "\n",
    "results_df = pd.DataFrame(rf_grid.cv_results_)\n",
    "print(f\"\\nTop 3 combinazioni di parametri:\")\n",
    "top_results = results_df.nlargest(3, 'mean_test_score')[['params', 'mean_test_score', 'std_test_score']]\n",
    "for idx, row in top_results.iterrows():\n",
    "    print(f\"  {row['params']} → MSE: {-row['mean_test_score']:.2f} (±{row['std_test_score']:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b4ca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = rf_grid.best_estimator_ \n",
    "results['Random Forest Optimized'] = evaluate_model(\n",
    "    best_rf, X_train_scaled, X_test_scaled, y_train, y_test, \"Random Forest Ottimizzato\"\n",
    ")\n",
    "\n",
    "\n",
    "final_comparison = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'Test MSE': [results[model]['test_mse'] for model in results.keys()],\n",
    "    'Test R²': [results[model]['test_r2'] for model in results.keys()],\n",
    "    'RMSE': [np.sqrt(results[model]['test_mse']) for model in results.keys()]\n",
    "})\n",
    "\n",
    "final_comparison = final_comparison.sort_values('Test MSE')\n",
    "print(\"\\nRISULTATI FINALI (ordinati dal migliore al peggiore):\")\n",
    "print(final_comparison)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(final_comparison['Model'], final_comparison['Test R²'])\n",
    "plt.title('Confronto R² Test Set per Modello')\n",
    "plt.ylabel('R² Score (più alto = migliore)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc69cdf",
   "metadata": {},
   "source": [
    "## Validazione Approfondita del Modello\n",
    "\n",
    "### Come si comporta il nostro miglior modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad03a26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_best = best_rf.predict(X_test_scaled)\n",
    "residuals = y_test - y_pred_best\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Previsioni vs valori reali \n",
    "plt.subplot(2, 3, 1)\n",
    "plt.scatter(y_test, y_pred_best, alpha=0.6, s=1)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Valori Reali (kWh)')\n",
    "plt.ylabel('Previsioni (kWh)')\n",
    "plt.title('Previsioni vs Valori Reali')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Distribuzione degli errori \n",
    "plt.subplot(2, 3, 2)\n",
    "plt.hist(residuals, bins=50, alpha=0.7, edgecolor='black')\n",
    "plt.xlabel('Errori (kWh)')\n",
    "plt.ylabel('Frequenza')\n",
    "plt.title('Distribuzione degli Errori')\n",
    "plt.axvline(0, color='red', linestyle='--')\n",
    "\n",
    "# Q-Q plot \n",
    "plt.subplot(2, 3, 3)\n",
    "from scipy import stats\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.title('Test Normalità Errori')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Errori vs previsioni \n",
    "plt.subplot(2, 3, 4)\n",
    "plt.scatter(y_pred_best, residuals, alpha=0.6, s=1)\n",
    "plt.xlabel('Previsioni (kWh)')\n",
    "plt.ylabel('Errori (kWh)')\n",
    "plt.title('Errori vs Previsioni')\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Errori per tipo di carico \n",
    "plt.subplot(2, 3, 5)\n",
    "test_indices = X_test.index\n",
    "load_types_test = df.loc[test_indices, 'Load_Type']\n",
    "residuals_abs = np.abs(residuals)\n",
    "\n",
    "load_type_errors = pd.DataFrame({\n",
    "    'Load_Type': load_types_test,\n",
    "    'Absolute_Error': residuals_abs\n",
    "}).groupby('Load_Type')['Absolute_Error'].mean()\n",
    "\n",
    "plt.bar(load_type_errors.index, load_type_errors.values)\n",
    "plt.xlabel('Tipo di Carico')\n",
    "plt.ylabel('Errore Assoluto Medio')\n",
    "plt.title('Errore per Tipo di Carico')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "feature_names = X_train_scaled.columns\n",
    "importances = best_rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.bar(range(len(importances)), importances[indices])\n",
    "plt.xlabel('Variabili')\n",
    "plt.ylabel('Importanza')\n",
    "plt.title('Importanza delle Variabili')\n",
    "plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Errore medio: {residuals.mean():.4f} kWh (dovrebbe essere vicino a 0)\")\n",
    "print(f\"Errore assoluto medio: {np.abs(residuals).mean():.4f} kWh\")\n",
    "print(f\"Errore massimo: {np.abs(residuals).max():.4f} kWh\")\n",
    "print(f\"95% degli errori sono sotto: {np.percentile(np.abs(residuals), 95):.4f} kWh\")\n",
    "\n",
    "# Test statistico per normalità degli errori\n",
    "shapiro_stat, shapiro_p = stats.shapiro(residuals[:5000])  # Campione per Shapiro-Wilk\n",
    "print(f\"\\nTest normalità errori (Shapiro-Wilk): p-value = {shapiro_p:.6f}\")\n",
    "if shapiro_p > 0.05:\n",
    "    print(\"Gli errori seguono una distribuzione normale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ddc931",
   "metadata": {},
   "source": [
    "### Confronto con Modelli Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e891720",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "print(\"Baseline 1: consumo medio\")\n",
    "baseline_mean = DummyRegressor(strategy='mean')\n",
    "baseline_mean.fit(X_train_scaled, y_train)\n",
    "y_pred_baseline_mean = baseline_mean.predict(X_test_scaled)\n",
    "\n",
    "print(\"Baseline 2: consumo mediano\")\n",
    "baseline_median = DummyRegressor(strategy='median')\n",
    "baseline_median.fit(X_train_scaled, y_train)\n",
    "y_pred_baseline_median = baseline_median.predict(X_test_scaled)\n",
    "\n",
    "print(\"Baseline 3: tipo di lavorazione\")\n",
    "baseline_loadtype = df.groupby('Load_Type')['Usage_kWh'].mean()\n",
    "test_indices = X_test.index\n",
    "load_types_test = df.loc[test_indices, 'Load_Type']\n",
    "y_pred_baseline_loadtype = load_types_test.map(baseline_loadtype).values\n",
    "\n",
    "# performance\n",
    "models_comparison = {\n",
    "    '(Media)': {\n",
    "        'MSE': mean_squared_error(y_test, y_pred_baseline_mean),\n",
    "        'R²': r2_score(y_test, y_pred_baseline_mean),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred_baseline_mean))\n",
    "    },\n",
    "    '(Mediana)': {\n",
    "        'MSE': mean_squared_error(y_test, y_pred_baseline_median),\n",
    "        'R²': r2_score(y_test, y_pred_baseline_median),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred_baseline_median))\n",
    "    },\n",
    "    '(Tipo Carico)': {\n",
    "        'MSE': mean_squared_error(y_test, y_pred_baseline_loadtype),\n",
    "        'R²': r2_score(y_test, y_pred_baseline_loadtype),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred_baseline_loadtype))\n",
    "    },\n",
    "    'Random Forest Ottimizzato': {\n",
    "        'MSE': mean_squared_error(y_test, y_pred_best),\n",
    "        'R²': r2_score(y_test, y_pred_best),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred_best))\n",
    "    }\n",
    "}\n",
    "\n",
    "comparison_final = pd.DataFrame(models_comparison).T\n",
    "print(\"(Ordinati dal migliore al peggiore per R²)\")\n",
    "print(comparison_final.sort_values('R²', ascending=False))\n",
    "\n",
    "baseline_r2_scores = comparison_final.loc[['(Media)', '(Mediana)', '(Tipo Carico)'], 'R²']\n",
    "best_baseline_r2 = baseline_r2_scores.max()\n",
    "our_model_r2 = comparison_final.loc['Random Forest Ottimizzato', 'R²']\n",
    "improvement = (our_model_r2 - best_baseline_r2) / best_baseline_r2 * 100\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# R² \n",
    "plt.subplot(2, 2, 1)\n",
    "models_names = list(models_comparison.keys())\n",
    "r2_scores = [models_comparison[model]['R²'] for model in models_names]\n",
    "colors = ['lightcoral', 'lightsalmon', 'lightblue', 'darkgreen']\n",
    "bars = plt.bar(range(len(models_names)), r2_scores, color=colors)\n",
    "plt.xlabel('Modelli')\n",
    "plt.ylabel('R² Score (più alto = migliore)')\n",
    "plt.title('Confronto R² - Tutti i Modelli')\n",
    "plt.xticks(range(len(models_names)), models_names, rotation=45, ha='right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bar, score in zip(bars, r2_scores):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, f'{score:.4f}',\n",
    "             ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "\n",
    "# errore medio\n",
    "plt.subplot(2, 2, 2)\n",
    "rmse_scores = [models_comparison[model]['RMSE'] for model in models_names]\n",
    "bars = plt.bar(range(len(models_names)), rmse_scores, color=colors)\n",
    "plt.xlabel('Modelli')\n",
    "plt.ylabel('RMSE (kWh) - più basso = migliore')\n",
    "plt.title('Confronto RMSE - Tutti i Modelli')\n",
    "plt.xticks(range(len(models_names)), models_names, rotation=45, ha='right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bar, score in zip(bars, rmse_scores):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, f'{score:.2f}',\n",
    "             ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "\n",
    "# Importanza variabili \n",
    "plt.subplot(2, 1, 2)\n",
    "feature_importance_final = pd.DataFrame({\n",
    "    'feature': X_train_scaled.columns,\n",
    "    'importance': best_rf.feature_importances_\n",
    "}).sort_values('importance', ascending=True)\n",
    "\n",
    "bars = plt.barh(range(len(feature_importance_final)), feature_importance_final['importance'])\n",
    "plt.yticks(range(len(feature_importance_final)), feature_importance_final['feature'])\n",
    "plt.xlabel('Importanza nel Modello')\n",
    "plt.title('Importanza delle Variabili - Random Forest Ottimizzato\\n(Quali variabili conta di più il modello per fare le previsioni?)')\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "\n",
    "bars[-1].set_color('darkgreen')\n",
    "bars[-1].set_alpha(0.8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b581c9",
   "metadata": {},
   "source": [
    "## Conclusioni Finali\n",
    "- **Modello milgiore**: Random Forest ottimizzato con R² = 0.9995 e RMSE = 0.78 kWh\n",
    "- **Variabile chiave**: `Lagging_Current_Reactive.Power_kVarh` spiega l'87% delle previsioni\n",
    "- **Problema identificato**: CO2 con correlazione 0.988 era troppo legata al target\n",
    "- **Variazioni orarie**: Il consumo cambia significativamente durante la giornata\n",
    "- **Tre tipi di carico**: Light, Medium, Maximum Load hanno consumi molto diversi\n",
    "- **Stagionalità**: Differenze mensili suggeriscono fattori climatici/produttivi\n",
    "- **Variabili elettriche**: Potenze reattive e fattori di potenza sono predittori chiave\n",
    "\n",
    "### **Valore Pratico per l'Industria**\n",
    "- **Monitoraggio real-time**: Accuratezza 99.95% per controllo operativo\n",
    "- **Rilevamento anomalie**: Il modello può identificare consumi anomali"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d372f98e",
   "metadata": {},
   "source": [
    "## Sviluppo Applicazione Web con Flask\n",
    "Questa applicazione permette di usare il modello tramite browser web\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56183aff",
   "metadata": {},
   "source": [
    "### Serializzazione del Modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86866a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import json\n",
    "import os\n",
    "\n",
    "required_vars = ['best_rf', 'scaler', 'label_encoders', 'numeric_features_clean', \n",
    "                 'categorical_features', 'X_encoded', 'our_model_r2', 'comparison_final']\n",
    "\n",
    "missing_vars = [var for var in required_vars if var not in globals()]\n",
    "\n",
    "model_filename = 'energy_prediction_model.pkl'\n",
    "joblib.dump(best_rf, model_filename)\n",
    "print(f\"Modello salvato : {model_filename}\")\n",
    "\n",
    "scaler_filename = 'scaler.pkl'\n",
    "joblib.dump(scaler, scaler_filename)\n",
    "print(f\"Scaler salvato: {scaler_filename}\")\n",
    "\n",
    "encoders_filename = 'label_encoders.pkl'\n",
    "joblib.dump(label_encoders, encoders_filename)\n",
    "\n",
    "metadata_filename = 'model_metadata.json'\n",
    "\n",
    "model_metadata = {\n",
    "    'numeric_features': numeric_features_clean,\n",
    "    'categorical_features': categorical_features,\n",
    "    'feature_names': list(X_encoded.columns),\n",
    "    'target_name': 'Usage_kWh',\n",
    "    'model_type': 'RandomForestRegressor',\n",
    "    'model_params': best_rf.get_params(),\n",
    "    'performance': {\n",
    "        'test_r2': float(our_model_r2),\n",
    "        'test_rmse': float(comparison_final.loc['Random Forest Ottimizzato', 'RMSE'])\n",
    "    },\n",
    "    'python_version': '3.13.2',\n",
    "    'creation_date': pd.Timestamp.now().isoformat()\n",
    "}\n",
    "\n",
    "with open(metadata_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(model_metadata, f, indent=2, ensure_ascii=False)\n",
    "print(f\"Metadati salvati: {metadata_filename}\")\n",
    "\n",
    "\n",
    "ranges_filename = 'feature_ranges.json'\n",
    "feature_ranges = {}\n",
    "\n",
    "for feature in numeric_features_clean:\n",
    "    if feature in df.columns:\n",
    "        feature_data = df[feature]\n",
    "        feature_ranges[feature] = {\n",
    "            'min': float(feature_data.min()),\n",
    "            'max': float(feature_data.max()),\n",
    "            'mean': float(feature_data.mean()),\n",
    "            'std': float(feature_data.std()),\n",
    "            'q25': float(feature_data.quantile(0.25)),\n",
    "            'q75': float(feature_data.quantile(0.75))\n",
    "        }\n",
    "\n",
    "for feature in categorical_features:\n",
    "    if feature in df.columns:\n",
    "        unique_values = df[feature].unique().tolist()\n",
    "        feature_ranges[feature] = {\n",
    "            'values': unique_values,\n",
    "            'counts': df[feature].value_counts().to_dict()\n",
    "        }\n",
    "\n",
    "with open(ranges_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(feature_ranges, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "\n",
    "print(f\"Copiare i file generati nella cartella 'web-app'\")\n",
    "print(f\"\\n Per avviare l'app: python web-app/app.py\")\n",
    "print(f\"http://localhost:5000\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
